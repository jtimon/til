mode test

import("self.lexer")

// ===== scan_tokens tests =====
// Test that escape sequences are properly processed by the lexer

test_newline_escape := proc() {
    mut source := "\"\\n\""
    mut tokens := scan_tokens(source)?

    tok := cast(Token, tokens.get(0)?)

    assert_eq_str(loc(), "\n", tok.token_str)

    // Catch unexpected errors at end
    catch (err: IndexOutOfBoundsError) {
        println("ERROR:", loc(), "Unexpected IndexOutOfBoundsError")
        println(err.msg)
        exit(1)
    }
    catch (err: Str) {
        println("ERROR:", loc(), "Unexpected Str error")
        println(err)
        exit(1)
    }
}
test_newline_escape()

test_tab_escape := proc() {
    mut source := "\"\\t\""
    mut tokens := scan_tokens(source)?

    tok := cast(Token, tokens.get(0)?)

    assert_eq_str(loc(), "\t", tok.token_str)

    // Catch unexpected errors at end
    catch (err: IndexOutOfBoundsError) {
        println("ERROR:", loc(), "Unexpected IndexOutOfBoundsError")
        println(err.msg)
        exit(1)
    }
    catch (err: Str) {
        println("ERROR:", loc(), "Unexpected Str error")
        println(err)
        exit(1)
    }
}
test_tab_escape()

test_carriage_return_escape := proc() {
    mut source := "\"\\r\""
    mut tokens := scan_tokens(source)?

    tok := cast(Token, tokens.get(0)?)

    assert_eq_str(loc(), "\r", tok.token_str)

    // Catch unexpected errors at end
    catch (err: IndexOutOfBoundsError) {
        println("ERROR:", loc(), "Unexpected IndexOutOfBoundsError")
        println(err.msg)
        exit(1)
    }
    catch (err: Str) {
        println("ERROR:", loc(), "Unexpected Str error")
        println(err)
        exit(1)
    }
}
test_carriage_return_escape()

test_null_escape := proc() {
    mut source := "\"\\0\""
    mut tokens := scan_tokens(source)?

    tok := cast(Token, tokens.get(0)?)

    assert_eq_str(loc(), "\0", tok.token_str)

    // Catch unexpected errors at end
    catch (err: IndexOutOfBoundsError) {
        println("ERROR:", loc(), "Unexpected IndexOutOfBoundsError")
        println(err.msg)
        exit(1)
    }
    catch (err: Str) {
        println("ERROR:", loc(), "Unexpected Str error")
        println(err)
        exit(1)
    }
}
test_null_escape()

test_multiple_escapes := proc() {
    mut source := "\"hello\\nworld\\ttab\""
    mut tokens := scan_tokens(source)?

    tok := cast(Token, tokens.get(0)?)

    assert_eq_str(loc(), "hello\nworld\ttab", tok.token_str)

    // Catch unexpected errors at end
    catch (err: IndexOutOfBoundsError) {
        println("ERROR:", loc(), "Unexpected IndexOutOfBoundsError")
        println(err.msg)
        exit(1)
    }
    catch (err: Str) {
        println("ERROR:", loc(), "Unexpected Str error")
        println(err)
        exit(1)
    }
}
test_multiple_escapes()

test_unknown_escape := proc() {
    // Unknown escape sequences should keep the backslash
    mut source := "\"\\x\""
    mut tokens := scan_tokens(source)?

    tok := cast(Token, tokens.get(0)?)

    assert_eq_str(loc(), "\\x", tok.token_str)

    // Catch unexpected errors at end
    catch (err: IndexOutOfBoundsError) {
        println("ERROR:", loc(), "Unexpected IndexOutOfBoundsError")
        println(err.msg)
        exit(1)
    }
    catch (err: Str) {
        println("ERROR:", loc(), "Unexpected Str error")
        println(err)
        exit(1)
    }
}
test_unknown_escape()

// ===== Lexer class tests =====

test_lexer_peek := proc() {
    // Create a simple test file
    mut lexer := Lexer.new(readfile("src/examples/empty.til")?)?

    // Peek at first token (should be "mode")
    first_token := lexer.peek()?
    assert_eq_str(loc(), "mode", first_token.token_str)

    // Peek again should return same token
    first_again := lexer.peek()?
    assert_eq_str(loc(), "mode", first_again.token_str)

    // Catch unexpected errors at end
    catch (err: Str) {
        println("ERROR:", loc(), "Unexpected Str error")
        println(err)
        exit(1)
    }
    catch (err: IndexOutOfBoundsError) {
        println("ERROR:", loc(), "Unexpected IndexOutOfBoundsError")
        println(err.msg)
        exit(1)
    }
    catch (err: ReadError) {
        println("ERROR:", loc(), "ReadError:", err.msg)
        exit(1)
    }
}
test_lexer_peek()

test_lexer_advance := proc() {
    mut lexer := Lexer.new(readfile("src/examples/empty.til")?)?

    // First token should be "mode"
    t1 := lexer.peek()?
    assert_eq_str(loc(), "mode", t1.token_str)

    // Advance and check next token
    lexer.advance(1)?
    t2 := lexer.peek()?
    assert_eq_str(loc(), "script", t2.token_str)

    // Catch unexpected errors at end
    catch (err: Str) {
        println("ERROR:", loc(), "Unexpected Str error")
        println(err)
        exit(1)
    }
    catch (err: IndexOutOfBoundsError) {
        println("ERROR:", loc(), "Unexpected IndexOutOfBoundsError")
        println(err.msg)
        exit(1)
    }
    catch (err: ReadError) {
        println("ERROR:", loc(), "ReadError:", err.msg)
        exit(1)
    }
}
test_lexer_advance()

test_lexer_peek_ahead := proc() {
    mut lexer := Lexer.new(readfile("src/examples/empty.til")?)?

    // Peek ahead by 1 (should be "script" while current is still "mode")
    next_token := lexer.peek_ahead(1)?
    assert_eq_str(loc(), "script", next_token.token_str)

    // Current token should still be "mode"
    current := lexer.peek()?
    assert_eq_str(loc(), "mode", current.token_str)

    // Catch unexpected errors at end
    catch (err: Str) {
        println("ERROR:", loc(), "Unexpected Str error")
        println(err)
        exit(1)
    }
    catch (err: IndexOutOfBoundsError) {
        println("ERROR:", loc(), "Unexpected IndexOutOfBoundsError")
        println(err.msg)
        exit(1)
    }
    catch (err: ReadError) {
        println("ERROR:", loc(), "ReadError:", err.msg)
        exit(1)
    }
}
test_lexer_peek_ahead()

test_lexer_next := proc() {
    mut lexer := Lexer.new(readfile("src/examples/empty.til")?)?

    // next() returns peek_ahead(1), so it returns the next token
    t1 := lexer.next()?
    assert_eq_str(loc(), "script", t1.token_str)

    // Current position hasn't changed (peek_ahead doesn't advance)
    t2 := lexer.peek()?
    assert_eq_str(loc(), "mode", t2.token_str)

    // Catch unexpected errors at end
    catch (err: Str) {
        println("ERROR:", loc(), "Unexpected Str error")
        println(err)
        exit(1)
    }
    catch (err: IndexOutOfBoundsError) {
        println("ERROR:", loc(), "Unexpected IndexOutOfBoundsError")
        println(err.msg)
        exit(1)
    }
    catch (err: ReadError) {
        println("ERROR:", loc(), "ReadError:", err.msg)
        exit(1)
    }
}
test_lexer_next()

test_lexer_previous := proc() {
    mut lexer := Lexer.new(readfile("src/examples/empty.til")?)?

    // Advance to "script"
    lexer.advance(1)?
    current := lexer.peek()?
    assert_eq_str(loc(), "script", current.token_str)

    // Get previous token (should be "mode")
    prev := lexer.previous()?
    assert_eq_str(loc(), "mode", prev.token_str)

    // Catch unexpected errors at end
    catch (err: Str) {
        println("ERROR:", loc(), "Unexpected Str error")
        println(err)
        exit(1)
    }
    catch (err: IndexOutOfBoundsError) {
        println("ERROR:", loc(), "Unexpected IndexOutOfBoundsError")
        println(err.msg)
        exit(1)
    }
    catch (err: ReadError) {
        println("ERROR:", loc(), "ReadError:", err.msg)
        exit(1)
    }
}
test_lexer_previous()

test_lexer_len := proc() {
    mut lexer := Lexer.new(readfile("src/examples/empty.til")?)?

    // empty.til should have at least 2 tokens: "mode" and "script"
    token_count := lexer.len()
    assert(loc(), gt(token_count, 1))

    // Catch unexpected errors at end
    catch (err: Str) {
        println("ERROR:", loc(), "Unexpected Str error")
        println(err)
        exit(1)
    }
    catch (err: ReadError) {
        println("ERROR:", loc(), "ReadError:", err.msg)
        exit(1)
    }
}
test_lexer_len()

test_lexer_get_token := proc() {
    mut lexer := Lexer.new(readfile("src/examples/empty.til")?)?

    // Get token at index 0
    t0 := lexer.get_token(0)?
    assert_eq_str(loc(), "mode", t0.token_str)

    // Get token at index 1
    t1 := lexer.get_token(1)?
    assert_eq_str(loc(), "script", t1.token_str)

    catch (err: Str) {
        println("ERROR:", loc(), "Unexpected Str error")
        println(err)
        exit(1)
    }
    catch (err: ReadError) {
        println("ERROR:", loc(), "ReadError:", err.msg)
        exit(1)
    }
}
test_lexer_get_token()

// Test namespace keyword is recognized (Issue #108)
test_namespace_keyword := proc() {
    mut source := "namespace"
    mut tokens := scan_tokens(source)?

    tok := cast(Token, tokens.get(0)?)

    assert_eq_str(loc(), "namespace", tok.token_str)
    // Verify it's recognized as a keyword, not an identifier
    switch tok.token_type {
    case TokenType.Namespace:
        // Good - it's the Namespace token
    case TokenType.Identifier:
        println("ERROR:", loc(), "namespace should be a keyword, not an identifier")
        exit(1)
    case:
        println("ERROR:", loc(), "namespace has unexpected token type")
        exit(1)
    }

    catch (err: IndexOutOfBoundsError) {
        println("ERROR:", loc(), "Unexpected IndexOutOfBoundsError")
        println(err.msg)
        exit(1)
    }
    catch (err: Str) {
        println("ERROR:", loc(), "Unexpected Str error")
        println(err)
        exit(1)
    }
}
test_namespace_keyword()
